{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "237108b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from numpy import asarray\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c862c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Ordinal Encoding\n",
    "\n",
    "In ordinal encoding, each unique category value is assigned an integer value.\n",
    "\n",
    "For example, “red” is 1, “green” is 2, and “blue” is 3.\n",
    "\n",
    "This is called an ordinal encoding or an integer encoding and is easily reversible. Often, integer values starting at zero are used.\n",
    "\n",
    "For some variables, an ordinal encoding may be enough. The integer values have a natural ordered relationship between each other and machine learning algorithms may be able to understand and harness this relationship.\n",
    "\n",
    "It is a natural encoding for ordinal variables. For categorical variables, it imposes an ordinal relationship where no such relationship may exist. This can cause problems and a one-hot encoding may be used instead.\n",
    "\n",
    "This ordinal encoding transform is available in the scikit-learn Python machine learning library via the OrdinalEncoder class.\n",
    "\n",
    "By default, it will assign integers to labels in the order that is observed in the data. If a specific order is desired, it can be specified via the “categories” argument as a list with the rank order of all expected labels.\n",
    "\n",
    "We can demonstrate the usage of this class by converting colors categories “red”, “green” and “blue” into integers. First the categories are sorted then numbers are applied. For strings, this means the labels are sorted alphabetically and that blue=0, green=1 and red=2.\n",
    "\n",
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ec02a51",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['red']\n",
      " ['green']\n",
      " ['blue']]\n",
      "[[2.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# define data\n",
    "data = asarray([['red'], ['green'], ['blue']])\n",
    "print(data)\n",
    "# define ordinal encoding\n",
    "encoder = OrdinalEncoder()\n",
    "# transform data\n",
    "result = encoder.fit_transform(data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc42f7b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This OrdinalEncoder class is intended for input variables that are organized into rows and columns, e.g. a matrix.\n",
    "\n",
    "If a categorical target variable needs to be encoded for a classification predictive modeling problem, then the LabelEncoder class can be used. It does the same thing as the OrdinalEncoder, although it expects a one-dimensional input for the single target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e84350",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# One-Hot Encoding\n",
    "\n",
    "For categorical variables where no ordinal relationship exists, the integer encoding may not be enough, at best, or misleading to the model at worst.\n",
    "\n",
    "Forcing an ordinal relationship via an ordinal encoding and allowing the model to assume a natural ordering between categories may result in poor performance or unexpected results (predictions halfway between categories).\n",
    "\n",
    "In this case, a one-hot encoding can be applied to the ordinal representation. This is where the integer encoded variable is removed and one new binary variable is added for each unique integer value in the variable.\n",
    "\n",
    "Each bit represents a possible category. If the variable cannot belong to multiple categories at once, then only one bit in the group can be “on.” This is called one-hot encoding …\n",
    "\n",
    "— Page 78, Feature Engineering for Machine Learning, 2018.\n",
    "\n",
    "In the “color” variable example, there are three categories, and, therefore, three binary variables are needed. A “1” value is placed in the binary variable for the color and “0” values for the other colors.\n",
    "\n",
    "This one-hot encoding transform is available in the scikit-learn Python machine learning library via the OneHotEncoder class.\n",
    "\n",
    "We can demonstrate the usage of the OneHotEncoder on the color categories. First the categories are sorted, in this case alphabetically because they are strings, then binary variables are created for each category in turn. This means blue will be represented as [1, 0, 0] with a “1” in for the first binary variable, then green, then finally red.\n",
    "\n",
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7a0f4db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['red']\n",
      " ['green']\n",
      " ['blue']]\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# define data \n",
    "data = asarray([['red'], ['green'], ['blue']])\n",
    "print(data)\n",
    "# define one hot encoding\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "# transform data\n",
    "onehot = encoder.fit_transform(data)\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8826eb4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Breast Cancer Dataset\n",
    "\n",
    "\n",
    "The dataset classifies breast cancer patient data as either a recurrence or no recurrence of cancer. There are 286 examples and nine input variables. It is a binary classification problem.\n",
    "\n",
    "A reasonable classification accuracy score on this dataset is between 68 percent and 73 percent. We will aim for this region, but note that the models in this demonstration are not optimized: they are designed to demonstrate encoding schemes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84c3398b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "url = 'https://media.githubusercontent.com/media/aurimas13/CodeAcademy-AI-Course/main/Examples/Data/medical.csv'\n",
    "dataset = pd.read_csv(url, header=None)\n",
    "# retrieve the array of data\n",
    "data = dataset.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7ea34b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once loaded, we can split the columns into input (X) and output (y) for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24911e99",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# seperate into input and output columns\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa59949",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Making use of this function, the complete example of loading and summarizing the raw categorical dataset is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3d91ef0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (286, 9)\n",
      "Output (286,)\n"
     ]
    }
   ],
   "source": [
    "# define the location of the dataset\n",
    "url = 'https://media.githubusercontent.com/media/aurimas13/CodeAcademy-AI-Course/main/Examples/Data/medical.csv'\n",
    "# load the dataset\n",
    "dataset = read_csv(url, header=None)\n",
    "# retrieve the array of data\n",
    "data = dataset.values\n",
    "# seperate into input and output columns\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "# summarize\n",
    "print('Input', X.shape)\n",
    "print('Output', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffd59f9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# OrdinalEncoder Transform\n",
    "\n",
    "\n",
    "An ordinal encoding involves mapping each unique label to an integer value.\n",
    "\n",
    "This type of encoding is really only appropriate if there is a known relationship between the categories. This relationship does exist for some of the variables in our dataset, and ideally, this should be harnessed when preparing the data.\n",
    "\n",
    "In this case, we will ignore any possible existing ordinal relationship and assume all variables are categorical. It can still be helpful to use an ordinal encoding, at least as a point of reference with other encoding schemes.\n",
    "\n",
    "We can use the OrdinalEncoder from scikit-learn to encode each variable to integers. This is a flexible class and does allow the order of the categories to be specified as arguments if any such order is known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a236c48e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ordinal encode input variables\n",
    "ordinal = OrdinalEncoder()\n",
    "X = ordinal.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "540acae2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ordinal encode targel variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e575e6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let’s try it on our breast cancer dataset.\n",
    "\n",
    "The complete example of creating an ordinal encoding transform of the breast cancer dataset and summarizing the result is listed below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9969b2e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (286, 9)\n",
      "[[2. 2. 2. 0. 1. 2. 1. 2. 0.]\n",
      " [3. 0. 2. 0. 0. 0. 1. 0. 0.]\n",
      " [3. 0. 6. 0. 0. 1. 0. 1. 0.]\n",
      " [2. 2. 6. 0. 1. 2. 1. 1. 1.]\n",
      " [2. 2. 5. 4. 1. 1. 0. 4. 0.]]\n",
      "Output (286,)\n",
      "[1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# define the location of the dataset\n",
    "url = 'https://media.githubusercontent.com/media/aurimas13/CodeAcademy-AI-Course/main/Examples/Data/medical.csv'\n",
    "# load the dataset\n",
    "dataset = read_csv(url, header=None)\n",
    "# retrieve the array of data\n",
    "data = dataset.values\n",
    "# seperate into input and output columns\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "# ordinal encode input variables\n",
    "ordinal = OrdinalEncoder()\n",
    "X = ordinal.fit_transform(X)\n",
    "# ordinal encode targel variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "# summarize the transformed data\n",
    "print('Input', X.shape)\n",
    "print(X[:5, :])\n",
    "print('Output', y.shape)\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8d50ed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, let’s evaluate machine learning on this dataset with this encoding.\n",
    "\n",
    "The best practice when encoding variables is to fit the encoding on the training dataset, then apply it to the train and test datasets.\n",
    "\n",
    "We will first split the dataset, then prepare the encoding on the training set, and apply it to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac25cf4d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd385f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can then fit the OrdinalEncoder on the training dataset and use it to transform the train and test datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16e2c1de",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ordinal encode input variables\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_encoder.fit(X_train)\n",
    "X_train = ordinal_encoder.transform(X_train)\n",
    "X_test = ordinal_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5e8d040",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.79\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit on training set \n",
    "model.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151d2d85",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Running the example prepares the dataset in the correct manner, then evaluates a model fit on the transformed data.\n",
    "\n",
    "Your specific results may differ given the stochastic nature of the algorithm and evaluation procedure.\n",
    "\n",
    "In this case, the model achieved a classification accuracy of about 75.79 percent, which is a reasonable score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637b2d23",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# OneHotEncoder Transform\n",
    "\n",
    "A one-hot encoding is appropriate for categorical data where no relationship exists between categories.\n",
    "\n",
    "The scikit-learn library provides the OneHotEncoder class to automatically one hot encode one or more variables.\n",
    "\n",
    "By default the OneHotEncoder will output data with a sparse representation, which is efficient given that most values are 0 in the encoded representation. We will disable this feature by setting the “sparse” argument to False so that we can review the effect of the encoding.\n",
    "\n",
    "Once defined, we can call the fit_transform() function and pass it to our dataset to create a quantile transformed version of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98da9828",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# one hot encode input variables\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "X = onehot_encoder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e4c4e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As before, we must label encode the target variable.\n",
    "\n",
    "The complete example of creating a one-hot encoding transform of the breast cancer dataset and summarizing the result is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2cd1d0c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (286, 43)\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# define the location of the dataset\n",
    "url = 'https://media.githubusercontent.com/media/aurimas13/CodeAcademy-AI-Course/main/Examples/Data/medical.csv'\n",
    "# load the dataset\n",
    "dataset = read_csv(url, header=None)\n",
    "# retrieve the array of data\n",
    "data = dataset.values\n",
    "# seperate intp input and output columns\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "# one hot encpode input variables\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "X = onehot_encoder.fit_transform(X)\n",
    "# label encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "# summarize the transformed data\n",
    "print('Input', X.shape)\n",
    "print(X[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c755b859",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, let’s evaluate machine learning on this dataset with this encoding as we did in the previous section.\n",
    "\n",
    "The encoding is fit on the training set then applied to both train and test sets as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d749b15",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# one hot encpode input variables\n",
    "onehot_encoder = OneHotEncoder()\n",
    "onehot_encoder.fit(X_train)\n",
    "X_train = onehot_encoder.transform(X_train)\n",
    "X_test = onehot_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe4794e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Final push give this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02916698",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.53\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit on training set \n",
    "model.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6153bd04",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Running the example prepares the dataset in the correct manner, then evaluates a model fit on the transformed data.\n",
    "\n",
    "Your specific results may differ given the stochastic nature of the algorithm and evaluation procedure.\n",
    "\n",
    "In this case, the model achieved a classification accuracy of about 70.53 percent, which is slightly worse than the ordinal encoding in the previous section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}